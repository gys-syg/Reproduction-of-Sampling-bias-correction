import sys
from pathlib import Path

p = Path.cwd()
# å‘ä¸ŠæŸ¥æ‰¾ç›´åˆ°æ‰¾åˆ° sbcnm_torch ç›®å½•æˆ–è¾¾åˆ°æ–‡ä»¶ç³»ç»Ÿæ ¹
while not (p / "sbcnm_torch").exists():
    if p.parent == p:
        raise RuntimeError("æœªåœ¨çˆ¶ç›®å½•ä¸­æ‰¾åˆ° sbcnm_torchï¼Œæ— æ³•è‡ªåŠ¨è®¾ç½® sys.pathï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šé¡¹ç›®æ ¹è·¯å¾„")
    p = p.parent
# å°†é¡¹ç›®æ ¹æ’å…¥åˆ° sys.path é¡¶éƒ¨ï¼ˆä¼˜å…ˆçº§é«˜ï¼‰
sys.path.insert(0, str(p))
print("Added to sys.path:", str(p))

import argparse
import numpy as np
import torch
from torch.utils.data import DataLoader
import math

from sbcnm_torch.utils.real_dataset import RealTwoTowerDataset
from sbcnm_torch.models.towers import QueryTower, ItemTower, DCNTower
from sbcnm_torch.models.query_embed_tower import QueryEmbedTower
from sbcnm_torch.models.item_gcn_tower import ItemGCNTower


@torch.no_grad()
def build_item_index(item_tower, i_feats_full, batch_size=1024, device="cpu"):
    """MLP/ä»»æ„å¡”ç‰ˆæœ¬ item å¡”ï¼šé€ batch å‰å‘ï¼Œæ‹¼æˆå…¨é‡ item embeddingã€‚"""
    item_tower.eval()
    embs = []
    for i in range(0, i_feats_full.shape[0], batch_size):
        e = item_tower(i_feats_full[i:i+batch_size].to(device))
        embs.append(e.cpu())
    embs = torch.cat(embs, dim=0)                     # [Ni, d]
    embs = torch.nn.functional.normalize(embs, p=2, dim=-1)
    return embs                                       


def recall_at_k(pred_ids, true_ids, k):
    # pred_ids: [B, K]  true_ids: [B]
    hits = (pred_ids[:, :k] == true_ids.view(-1, 1)).any(dim=1).float()
    return hits.mean().item()


def ndcg_at_k(pred_ids, true_ids, k):
    """äºŒåˆ†ç±» NDCGï¼šå‘½ä¸­åœ¨ä½ç½® rï¼Œåˆ™ DCG = 1/log2(r+2)ï¼ŒIDCG=1ã€‚"""
    B = pred_ids.shape[0]
    pos = (pred_ids[:, :k] == true_ids.view(-1, 1)).float()
    discounts = 1.0 / torch.log2(torch.arange(2, k + 2).float())
    dcg = (pos * discounts.to(pos.device)).max(dim=1).values  # ä¸€è¡Œæœ€å¤šä¸€ä¸ª1
    return dcg.mean().item()


def auc_score(pos_score: torch.Tensor, neg_scores: torch.Tensor) -> float:
    """
    pos_score: æ ‡é‡ tensorï¼Œæ­£æ ·æœ¬åˆ†æ•°
    neg_scores: [N_neg]ï¼Œè´Ÿæ ·æœ¬åˆ†æ•°
    è¿”å›å•ä¸ªç”¨æˆ·çš„ AUC = P( pos > neg )
    """
    return (pos_score > neg_scores).float().mean().item()


def load_model_from_ckpt(
    ckpt_path,
    ds,
    device,
    use_user_embed=False,
    user_embed_cfg=None,
    use_dcn_item=False,      # item ä¾§æ˜¯å¦ DCN
):
    """
    ä» ckpt é‡Œæ¢å¤ query_tower å’Œ item_towerã€‚

    - use_user_embed=True  â†’ ç”¨ QueryEmbedTower
    - use_user_embed=False â†’ ç”¨ QueryTower æˆ– DCNTowerï¼ˆè‡ªåŠ¨æ ¹æ® ckpt åˆ¤æ–­ï¼‰
    - use_dcn_item=True    â†’ item ä¾§ç”¨ DCNTowerï¼ˆä¸ä½ çš„ dcn_ckpt å¯¹åº”ï¼‰
    """
    state = torch.load(ckpt_path, map_location=device)
    cfg = state["config"]

    # === item tower ===
    if use_dcn_item:
        # DCN å‚æ•°å°½é‡å’Œè®­ç»ƒæ—¶ä¿æŒä¸€è‡´
        item_tower = DCNTower(
            in_dim=ds.i_feats.shape[1],
            num_cross=cfg.get("cross_layers", 3),
            deep_hidden=(cfg.get("h1", 256), cfg.get("h2", 128)),
            out_dim=cfg.get("out_dim", 64),
            l2norm=True,
        ).to(device)
    else:
        item_tower = ItemTower(
            in_dim=ds.i_feats.shape[1],
            hidden=(cfg.get("h1", 256), cfg.get("h2", 128)),
            out_dim=cfg.get("out_dim", 64),
            l2norm=True
        ).to(device)

    item_tower.load_state_dict(state["item_state"])
    item_tower.eval()

    # === query tower ===
    q_state = state["query_state"]

    if use_user_embed:
        # è¿™ä¸€æ”¯æ˜¯ä½  user-embed é‚£æ¡çº¿ï¼ˆQueryEmbedTowerï¼‰
        assert user_embed_cfg is not None, "use_user_embed=True æ—¶å¿…é¡»æä¾› user_embed_cfg"
        qe = QueryEmbedTower(
            num_users=ds.q_feats.shape[0],
            gender_vocab=user_embed_cfg["gender_vocab"],
            age_buckets=user_embed_cfg["age_buckets"],
            occ_vocab=user_embed_cfg["occ_vocab"],
            id_dim=user_embed_cfg["id_dim"],
            g_dim=user_embed_cfg["g_dim"],
            a_dim=user_embed_cfg["a_dim"],
            o_dim=user_embed_cfg["o_dim"],
            dense_in=ds.q_feats.shape[1] if user_embed_cfg["use_query_dense"] else 0,
            mlp_hidden=(cfg.get("h1", 256),),
            out_dim=cfg.get("out_dim", 64),
            l2norm=True
        ).to(device)
        qe.load_state_dict(q_state)
        qe.eval()
        query_tower = qe
    else:
        # è¿™ä¸€æ”¯æ˜¯ã€Œä¸å¸¦ user-embedã€çš„ç‰ˆæœ¬ï¼Œæœ‰ä¸¤ç§å¯èƒ½ï¼š
        # - æ—§çš„ MLP QueryTowerï¼ˆstate é‡Œçš„ key å« net.*ï¼‰
        # - DCN ç‰ˆ Queryï¼ˆstate é‡Œçš„ key å« cross_layers./deep./out.ï¼‰
        q_keys = list(q_state.keys())
        has_dcn = any(
            k.startswith("cross_layers") or k.startswith("deep.") or k.startswith("out.")
            for k in q_keys
        )

        if has_dcn:
            # ğŸ‘‰ è¯´æ˜ ckpt é‡Œçš„ query_tower å…¶å®æ˜¯ DCNTower
            qt = DCNTower(
                in_dim=ds.q_feats.shape[1],
                num_cross=cfg.get("cross_layers", 3),
                deep_hidden=(cfg.get("h1", 256), cfg.get("h2", 128)),
                out_dim=cfg.get("out_dim", 64),
                l2norm=True,
            ).to(device)
        else:
            # ğŸ‘‰ æ™®é€šçš„ MLP QueryTower
            qt = QueryTower(
                in_dim=ds.q_feats.shape[1],
                hidden=(cfg.get("h1", 256), cfg.get("h2", 128)),
                out_dim=cfg.get("out_dim", 64),
                l2norm=True
            ).to(device)

        qt.load_state_dict(q_state)
        qt.eval()
        query_tower = qt

    return query_tower, item_tower, cfg


@torch.no_grad()
def evaluate_sampled(
    ckpt_path,
    args,
    split="valid",
    use_user_embed=False,
    user_embed_cfg=None,
    use_dcn_item=False,
    num_neg=99,
):
    """
    è®ºæ–‡/æ¯”èµ›å¸¸ç”¨è¯„ä¼°æ–¹å¼ï¼š
    å¯¹æ¯ä¸ª userï¼Œåœ¨ {1 ä¸ªæ­£æ ·æœ¬ + num_neg ä¸ªéšæœºè´Ÿæ ·æœ¬} çš„å€™é€‰é›†åˆä¸Šï¼Œ
    è®¡ç®— Recall@K / NDCG@K / AUCã€‚

    æ³¨æ„ï¼šè¿™é‡Œä¸å†ç”¨â€œå…¨åº“ topKâ€ï¼Œè€Œæ˜¯â€œé‡‡æ · topKâ€ã€‚
    """
    device = torch.device("cuda" if torch.cuda.is_available() and not args.cpu else "cpu")

    ds = RealTwoTowerDataset(
        args.q_feats_npy,
        args.q_idmap_csv,
        args.i_feats_npy,
        args.i_idmap_csv,
        args.inter_csv,
        split=split,
        q_side_cat_npy=(args.q_side_cat_npy if use_user_embed else None),
    )
    print(f"âœ… RealTwoTowerDataset[{split}] æ ·æœ¬æ•°: {len(ds)}")
    loader = DataLoader(ds, batch_size=args.batch_size, shuffle=False, drop_last=False)

    # åŠ è½½æ¨¡å‹
    query_tower, item_tower, cfg = load_model_from_ckpt(
        ckpt_path,
        ds,
        device,
        use_user_embed=use_user_embed,
        user_embed_cfg=user_embed_cfg,
        use_dcn_item=use_dcn_item,
    )

    # é¢„è®¡ç®—å…¨é‡ item embedding
    i_feats_full = torch.tensor(ds.i_feats, dtype=torch.float32, device=device)
    item_embs = build_item_index(item_tower, i_feats_full, batch_size=2048, device=device)
    Ni = item_embs.shape[0]

    Ks = [5, 10, 50]
    sums_recall = {k: 0.0 for k in Ks}
    sums_ndcg = {k: 0.0 for k in Ks}
    sum_auc = 0.0
    n_user = 0

    for batch in loader:
        # è®¡ç®— query embedding
        if use_user_embed:
            q_emb = query_tower(
                user_row=batch["q_row"].to(device),
                gender_idx=batch["q_gender_idx"].to(device),
                age_idx=batch["q_age_idx"].to(device),
                occ_idx=batch["q_occ_idx"].to(device),
                query_dense=(
                    batch["query_feat"].to(device)
                    if user_embed_cfg["use_query_dense"]
                    else None
                ),
            )  # [B,d]
        else:
            q_emb = query_tower(batch["query_feat"].to(device))  # [B,d]

        true_ids = batch["pos_item_row"].to(device).long()       # [B]
        B = q_emb.shape[0]

        for b in range(B):
            pos = true_ids[b].item()

            # === é‡‡æ · num_neg ä¸ªè´Ÿæ ·æœ¬ï¼ˆä¸åŒ…å« posï¼‰ ===
            # trickï¼šå…ˆåœ¨ [0, Ni-1] é‡‡æ ·ï¼Œå†æŠŠ >= pos çš„ç´¢å¼•æ•´ä½“ +1ï¼Œè·³è¿‡æ­£æ ·æœ¬
            idx = torch.randint(0, Ni - 1, (num_neg,), device=device)
            neg_ids = idx + (idx >= pos).long()   # [num_neg]
            cand_ids = torch.cat(
                [torch.tensor([pos], device=device, dtype=torch.long), neg_ids],
                dim=0
            )  # [1 + num_neg]

            # è®¡ç®—è¿™ 1+num_neg ä¸ªå€™é€‰çš„åˆ†æ•°
            scores = (q_emb[b:b+1] @ item_embs[cand_ids].to(device).T).squeeze(0)  # [C]
            pos_score = scores[0]
            neg_scores = scores[1:]

            # è®¡ç®— rankï¼ˆåœ¨å€™é€‰é›†åˆå†…éƒ¨çš„åæ¬¡ï¼Œ0 ä¸º bestï¼‰
            _, sorted_idx = scores.sort(descending=True)
            rank = (sorted_idx == 0).nonzero(as_tuple=False).item()  # 0-based

            # Recall & NDCGï¼ˆåœ¨é‡‡æ ·é›†åˆä¸Šçš„ç‰ˆæœ¬ï¼‰
            for k in Ks:
                if rank < k:
                    sums_recall[k] += 1.0
                    sums_ndcg[k] += 1.0 / math.log2(rank + 2)  # rank ä»0å¼€å§‹ï¼Œæ‰€ä»¥ +2
            # AUCï¼ˆpos vs neg_scoresï¼‰
            sum_auc += auc_score(pos_score, neg_scores)

            n_user += 1

    metrics = {f"Recall@{k}": sums_recall[k] / n_user for k in Ks}
    metrics.update({f"NDCG@{k}": sums_ndcg[k] / n_user for k in Ks})
    metrics["AUC"] = sum_auc / n_user
    return metrics


def main():
    p = argparse.ArgumentParser()
    # æ•°æ®è·¯å¾„
    p.add_argument("--q_feats_npy", type=str, required=True)
    p.add_argument("--q_idmap_csv", type=str, required=True)
    p.add_argument("--i_feats_npy", type=str, required=True)
    p.add_argument("--i_idmap_csv", type=str, required=True)
    p.add_argument("--inter_csv", type=str, required=True)
    p.add_argument("--q_side_cat_npy", type=str, default="")  # åªæœ‰ user-embed æ—¶ç”¨

    # ckpt è·¯å¾„
    p.add_argument("--dcn_bias_ckpt", type=str, required=True)  # DCN çº åç‰ˆæœ¬
    p.add_argument("--dcn_nobias_ckpt", type=str, required=True)  # DCN ä¸çº åç‰ˆæœ¬

    # å…¶å®ƒ
    p.add_argument("--batch_size", type=int, default=512)
    p.add_argument("--cpu", action="store_true")
    args = p.parse_args()

    # user-embed é…ç½®ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
    user_embed_cfg = dict(
        gender_vocab=2,
        age_buckets=7,
        occ_vocab=21,
        id_dim=32,
        g_dim=4,
        a_dim=8,
        o_dim=8,
        use_query_dense=True,
    )

    # ========= 1. DCN (çº åç‰ˆæœ¬) =========
    print("== Evaluate DCN (Bias Correction) Version ==")
    m_dcn_bias = evaluate_sampled(
        args.dcn_bias_ckpt,
        args,
        split="valid",
        use_user_embed=False,  # æ ¹æ®éœ€è¦è®¾å®š
        use_dcn_item=True,     # ä½¿ç”¨ DCN item å¡”
        num_neg=99,
    )
    for k, v in m_dcn_bias.items():
        print(f"{k}: {v:.4f}")

    # ========= 2. DCN (ä¸çº åç‰ˆæœ¬) =========
    print("\n== Evaluate DCN (No Bias Correction) Version ==")
    m_dcn_nobias = evaluate_sampled(
        args.dcn_nobias_ckpt,
        args,
        split="valid",
        use_user_embed=False,  # æ ¹æ®éœ€è¦è®¾å®š
        use_dcn_item=True,     # ä½¿ç”¨ DCN item å¡”
        num_neg=99,
    )
    for k, v in m_dcn_nobias.items():
        print(f"{k}: {v:.4f}")

    # ========= å·®å€¼å¯¹æ¯” =========
    print("\n== Î” (DCN with Bias Correction - DCN without Bias Correction) ==")
    for k in m_dcn_bias.keys():
        print(f"{k}: {m_dcn_bias[k] - m_dcn_nobias[k]:+.4f}")


if __name__ == "__main__":
    main()
